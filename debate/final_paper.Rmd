---
title: "Text as Data Final Paper"
author: "Jacqueline Gutman, Alex Pine"
date: "May 10, 2016"
output: pdf_document
---

```{r setup, include=FALSE}
# setwd("~/Desktop/Text as Data/texas/debate/")
load("project_jackie.RData")
knitr::opts_chunk$set(echo=TRUE, cache=TRUE, warning=FALSE, comment="   ",
    fig.align='center', fig.width = 4.0, fig.height = 3.5)
require(dplyr)
require(lme4)
require(quanteda)
require(glmnet)
```

```{r, warning=FALSE, message=FALSE}
# LDA model for debate: debate_LDA_15
# topic names for debate: debate_LDA_15_names
# data frame for twitter: twitter.df
# dfm for twitter: twitter_dfm
# posterior topic distribution (LDA) = @gamma
# LDA model for twitter: use simple_lda_20, simple_lda_15, simple_lda_10
# LDA posterior for twitter using debate topics: twitter.topics$topics
all(nrow(twitter_dfm) == sum(twitter.df$debate_topic != 0),
    nrow(twitter_dfm)  == nrow(twitter.topics$topics))
table(twitter.df$debate_topic)
debate_LDA_15_names
```

```{r}
# pos.neg <- dplyr::select(twitter.df[tweet_indices,], -tweet_created)
# pos.neg <- filter(pos.neg, sentiment != "Neutral")
# pos.neg$candidate[pos.neg$candidate == "OTHER"] <- NA
# pos.neg$subject_matter[pos.neg$subject_matter == "None of the above"] <- NA
# pos.neg <- droplevels(pos.neg)
levels(pos.neg$sentiment)
levels(pos.neg$candidate)
levels(pos.neg$subject_matter)
dropped.rows <- which(twitter.df[tweet_indices, "sentiment"] == "Neutral")
nrow(pos.neg) + length(dropped.rows) == nrow(twitter.topics$topics)
all(dim(simple_lda_15@gamma) == dim(twitter.topics$topics), 
    class(simple_lda_15@gamma) == class(twitter.topics$topics))
dim(simple_lda_25@gamma[-dropped.rows,])
dim(twitter.topics$topics[-dropped.rows,])
all(abs(rowSums(simple_lda_25@gamma) - 1) < 1e-10) 
all(abs(rowSums(twitter.topics$topics) - 1) < 1e-10) 
```

```{r}
# build a logistic regression from lda model parameters, additional predictors as parameter
glm_lda_model <- function(lda_model_post, modified_data, 
                          predictors = c("candidate", "subject_matter")) {
    x <- lda_model_post[,-2] # need to drop one of the topics, I drop #2
    colnames(x) <- paste("topic", 1:(ncol(x)+1), sep=".")[-2]
    data <- cbind(modified_data, x)
    formula <- paste("sentiment ~ ", 
                    paste(c(colnames(x), predictors), collapse = " + "))
    fit <- glm(as.formula(formula) , data = data, family = "binomial")
    print(summary(fit))
    fit
} 

# use forward-backward stepwise procedure with AIC criterion to choose best model from full model
stepwise_twitter <- function(lda_model_post, modified_data, 
                        predictors = c("candidate", "subject_matter")) {
  x <- lda_model_post # don't drop any topics
  colnames(x) <- paste("topic", 1:(ncol(x)), sep=".")
  data <- cbind(modified_data, x)
  formula <- paste("sentiment ~ ", 
                   paste(c(colnames(x), predictors), collapse = " + "))
  fit <- glm(as.formula(formula) , data = data, family = "binomial")
  stepAIC(fit, trace = FALSE) # stops verbose printing
}
```

```{r}
pos.neg.sub <- pos.neg[c("sentiment", "candidate", "subject_matter")]
levels(pos.neg.sub$candidate) <- c(levels(pos.neg.sub$candidate), "other")
pos.neg.sub$candidate <- relevel(pos.neg.sub$candidate, ref = "other")
pos.neg.sub$candidate[is.na(pos.neg.sub$candidate)] <- "other"
levels(pos.neg.sub$subject_matter) <- c(levels(pos.neg.sub$subject_matter), "other")
pos.neg.sub$subject_matter[is.na(pos.neg.sub$subject_matter)] <- "other"
pos.neg.sub$subject_matter <- relevel(pos.neg.sub$subject_matter, ref = "other")

dummy_candidate <- dummy(pos.neg.sub$candidate, 
                         levels(pos.neg.sub$candidate)[-1])
dummy_subject_matter <- dummy(pos.neg.sub$subject_matter, 
                         levels(pos.neg.sub$subject_matter)[-1])
candidate_only <- cv.glmnet(x = dummy_candidate, y = pos.neg.sub$sentiment, 
          family = "binomial", alpha = 1, nfolds = 10)
candidate_subject_only <- cv.glmnet(x = cbind(dummy_candidate, dummy_subject_matter), 
          y = pos.neg.sub$sentiment, family = "binomial", alpha = 1, nfolds = 10)
min(candidate_only$cvm)
min(candidate_subject_only$cvm)
coef(candidate_only, s="lambda.min")
coef(candidate_subject_only, s="lambda.min")

```

```{r, eval=FALSE}
sentiment_twitter_candidate_10 <- glm_lda_model(simple_lda_10@gamma[-dropped.rows,] ,
                              modified_data = pos.neg.sub, predictors = "candidate")
sentiment_twitter_candidate_15 <- glm_lda_model(simple_lda_15@gamma[-dropped.rows,] ,
                              modified_data = pos.neg.sub, predictors = "candidate")
sentiment_twitter_candidate_20 <- glm_lda_model(simple_lda_20@gamma[-dropped.rows,] ,
                              modified_data = pos.neg.sub, predictors = "candidate")
sentiment_twitter_candidate_25 <- glm_lda_model(simple_lda_25@gamma[-dropped.rows,] ,
                              modified_data = pos.neg.sub, predictors = "candidate")
sentiment_twitter_candidate_30 <- glm_lda_model(simple_lda_30@gamma[-dropped.rows,] ,
                              modified_data = pos.neg.sub, predictors = "candidate")
sentiment_twitter_candidate_50 <- glm_lda_model(simple_lda_50@gamma[-dropped.rows,] ,
                              modified_data = pos.neg.sub, predictors = "candidate")
```

```{r}
which.max(c(k10 = simple_lda_10@loglikelihood, k15 = simple_lda_15@loglikelihood, 
            k20 = simple_lda_20@loglikelihood, k25 = simple_lda_25@loglikelihood, 
            k30 = simple_lda_30@loglikelihood, k50 = simple_lda_50@loglikelihood))
which.min(c(k10 = AIC(sentiment_twitter_candidate_10), k15 = AIC(sentiment_twitter_candidate_15),
          k20 = AIC(sentiment_twitter_candidate_20), k25 = AIC(sentiment_twitter_candidate_25),
          k30 = AIC(sentiment_twitter_candidate_30), k50 = AIC(sentiment_twitter_candidate_50)))
sort(c(k10 = BIC(sentiment_twitter_candidate_10), k15 = BIC(sentiment_twitter_candidate_15),
            k20 = BIC(sentiment_twitter_candidate_20), k25 = BIC(sentiment_twitter_candidate_25),
            k30 = BIC(sentiment_twitter_candidate_30), k50 = BIC(sentiment_twitter_candidate_50)),
     decreasing = TRUE)

anova(sentiment_twitter_candidate_20, sentiment_twitter_candidate_25, test="Chisq")
anova(sentiment_twitter_candidate_25, sentiment_twitter_candidate_50, test="Chisq")
```

```{r}
sentiment_debate_candidate <- glm_lda_model(twitter.topics$topics[-dropped.rows,] ,
                                modified_data = pos.neg.sub, predictors = "candidate")
AIC(sentiment_debate_candidate); BIC(sentiment_debate_candidate)
AIC(sentiment_twitter_candidate_25); BIC(sentiment_twitter_candidate_25)
anova(sentiment_debate_candidate, sentiment_twitter_candidate_25, test="Chisq")
```

```{r}
require(MASS)
step_25_candidate_subject <- stepwise_twitter(simple_lda_25@gamma[-dropped.rows,], 
                            pos.neg.sub, predictors = c("candidate", "subject_matter"))
step_25_candidate_subject$anova
summary(step_25_candidate_subject)

step_debate_topics <- stepwise_twitter(twitter.topics$topics[-dropped.rows,],  
                        pos.neg.sub, predictors = c("candidate", "subject_matter"))
step_debate_topics$anova
summary(step_debate_topics)
anova(step_debate_topics, step_25_candidate_subject, test="Chisq")
```

```{r}
dummy_candidate <- dummy(pos.neg.sub$candidate, 
                         levels(pos.neg.sub$candidate)[-1])
dummy_subject_matter <- dummy(pos.neg.sub$subject_matter, 
                         levels(pos.neg.sub$subject_matter)[-1])
candidate_only <- cv.glmnet(x = dummy_candidate, y = pos.neg.sub$sentiment, 
          family = "binomial", alpha = 1, nfolds = 10)
candidate_subject_only <- cv.glmnet(x = cbind(dummy_candidate, dummy_subject_matter), 
          y = pos.neg.sub$sentiment, family = "binomial", alpha = 1, nfolds = 10)
min(candidate_only$cvm)
min(candidate_subject_only$cvm)
coef(candidate_only, s="lambda.min")
coef(candidate_subject_only, s="lambda.min")
```

```{r}
require(coefplot)
candidate_only2 <- glm(sentiment ~ candidate, data = pos.neg.sub, family = "binomial")
candidate_subject_only2 <- glm(sentiment ~ candidate + subject_matter, data = pos.neg.sub, 
                               family = "binomial")
summary(candidate_only2)
rename_candidate <- c("other", gsub("candidate*", "", names(coef(candidate_only2))[2:11]))
names(rename_candidate) <- names(coef(candidate_only2))
coefplot::coefplot(candidate_only2, sort="magnitude", newNames = rename_candidate)

summary(candidate_subject_only2)
rename_subject <- c("other", gsub("subject_matter*", "", names(coef(candidate_subject_only2))[12:22]))
names(rename_subject) <- names(coef(candidate_subject_only2))[c(1,12:22)]
#coefplot::coefplot(candidate_subject_only2, predictors = "subject_matter", sort="magnitude", newNames = rename_subject)
anova(candidate_only2, candidate_subject_only2, test = "Chisq")
```